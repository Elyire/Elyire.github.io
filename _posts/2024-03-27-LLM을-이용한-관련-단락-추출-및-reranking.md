---
title: í”„ë¡¬í”„íŠ¸ ì²´ì¸(Prompt Chain)ì„ ì´ìš©í•œ ê²€ìƒ‰ì´í›„(Post-Retrieval) í”„ë¡œì„¸ìŠ¤
date: 2024-03-28 17:20:00 +09:00
categories: [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, í”„ë¡¬í”„íŠ¸ ì‘ì„±ê¸°ë²•]
tags: [RAG, í”„ë¡¬í”„íŠ¸ ì‘ì„±ê¸°ë²•, ë­ì²´ì¸]
pin: false
---

## í”„ë¡¬í”„íŠ¸ ì²´ì¸(Prompt Chain)

í”„ë¡¬í”„íŠ¸ ì²´ì¸(prompt chain í˜¹ì€ prompt chaining)ì€ task ìˆ˜í–‰ì„ ìœ„í•´ 2ê°œ ì´ìƒì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ì ‘ê·¼ë²•ìœ¼ë¡œì„œ, ì´ì „ í”„ë¡¬í”„íŠ¸ ì§€ì‹œ(instruction)ì— ì˜í•œ ì¶œë ¥ ê²°ê³¼ë¥¼ ë‹¤ìŒ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì˜ ë‚´ìš©ì˜ ì¼ë¶€ë¡œ í¬í•¨ì‹œì¼œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´, LLMì´ ì£¼ì–´ì§„ ì•„í‹°í´ì„ ê²€ì‚¬í•˜ì—¬ ë¬¸ë²• ì˜¤ë¥˜ ëª©ë¡ì„ ì‘ì„±í•˜ê³ , ì´ ëª©ë¡ì´ ë¹ ì§ì—†ì´ ì‘ì„±ë˜ì—ˆëŠ”ì§€ëŠ” í™•ì¸í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— í”„ë¡¬í”„íŠ¸ ì²´ì¸ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤.[1]

ì²«ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ëŠ” ì´ìš©í•´ ë¬¸ë²• ì˜¤ë¥˜ ëª©ë¡ì„ ìƒì„±í•˜ë„ë¡ ì§€ì‹œí•œë‹¤.

```
Here is an article:
<article>
{ARTICLE}
</article>

Please identify any grammatical errors in the article. 
Please only respond with the list of errors, and nothing else. 
If there are no grammatical errors, say "There are no errors."
```

ì²«ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ìƒì„±ëœ ë¬¸ë²• ì˜¤ë¥˜ ëª©ë¡ì„ {ERRORS}ë¼ê³  í•œë‹¤ë©´, ë‘ ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ì— ì´ë¥¼ ì¶”ê°€í•˜ì—¬ ë¬¸ë²• ì˜¤ë¥˜ ëª©ë¡ì— ë¹ ì§„ ë‚´ìš©ì´ ì—†ëŠ”ì§€ í™•ì¸í•˜ë„ë¡ ì§€ì‹œí•œë‹¤.  

```
Here is an article:
<article>
{ARTICLE}
</article>

Please identify any grammatical errors in the article that are missing from the following list:
<list>
{ERRORS}
</list>

If there are no errors in the article that are missing from the list, say "There are no additional errors."
```


## í”„ë¡¬í”„íŠ¸ ì²´ì¸(Prompt Chain) ê¸°ë°˜ ê²€ìƒ‰ì´í›„(Post-Retrieval) í”„ë¡œì„¸ìŠ¤

íš¨ê³¼ì ì¸ ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•´, êµ¬ì¶•ëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ê²€ìƒ‰ê¸°(í˜¹ì€ ë¦¬íŠ¸ë¦¬ë²„, retriever)ë¥¼ ì´ìš©í•´ ì¿¼ë¦¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¨ í›„, ì´ ë¬¸ì„œë“¤ì— ì¶”ê°€ì ì¸ ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ë“¤ì´ ì‹œë„ë˜ì–´ ì™”ë‹¤ (RankGPT[2], RAG-Fusion[3], CRAG[4] ë“±).  

ë¬¸ë“ ë³µì¡í•œ í”„ë¡œê·¸ë˜ë° ì—†ì´, ìˆœìˆ˜í•˜ê²Œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ë§Œìœ¼ë¡œ ê²€ìƒ‰ì´í›„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì ìš©í•´ë³´ë©´ ì–´ë–¨ê¹Œ í•˜ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤.

1) ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ê¸°ì¡´ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì´ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê°€ì ¸ì˜¨ë‹¤.  
2) LLMì„ ì´ìš©í•´(ì¦‰, í”„ë¡¬í”„íŠ¸ë¥¼ ì´ìš©í•´) retrieved docs ì¤‘, ì¿¼ë¦¬ì™€ ê¹Šì€ ê´€ë ¨ì´ ìˆëŠ” ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ì„ ë¦¬ìŠ¤íŠ¸ì—…í•˜ê³  ìˆœìœ„ë¥¼ ë§¤ê¸´ë‹¤.  
3) ìˆœìœ„ê°€ ë§¤ê²¨ì§„ ê´€ë ¨ ë¬¸ì¥ í˜¹ì€ ë‹¨ë½ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ìš©í•´ ìµœì¢…ë‹µë³€ì„ LLMì´ ìƒì„±í•˜ê²Œ í•œë‹¤.  

ì¦‰, ì¿¼ë¦¬ì— ëŒ€í•œ ìµœì¢…ë‹µë³€ì— í•„ìš”í•œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì‹œë§¨í‹± ê²€ìƒ‰ê³¼ LLMì˜ ëŠ¥ë ¥ì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ë§Œì•½ ë‚´ê°€ ì–´ë–¤ retrieved documentsë¥¼ ëˆ„êµ°ê°€ë¡œë¶€í„° ë°›ì•„ì„œ,  ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ë§Œë“¤ì–´ì•¼ í•œë‹¤ë©´ ì–´ë–¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ê±°ì¹ ê¹Œë¥¼ ìƒê°í•´ ë´¤ë‹¤. ë‚˜ë¼ë©´ ë¨¼ì € ë‚´ê²Œ ì£¼ì–´ì§„ retrieved documents(ì•„ë§ˆë„ ì„œë¥˜ ë­‰íƒ±ì´ì¼ìˆ˜ë„ ìˆê² ë‹¤)ë¡œë¶€í„° ì§ˆë¬¸ ë‹µë³€ì— í•„ìš”í•œ ë¬¸ì¥ì´ë‚˜ ë¬¸ë‹¨ì„ ê³¨ë¼ ë”°ë¡œ ì ì–´ë†“ê³ , ì´ë ‡ê²Œ ì„ ë³„ëœ ë¬¸ì¥ì´ë‚˜ ë¬¸ë‹¨ì„ í™œìš©í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•  ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. 

ìœ„ì˜ ì•„ì´ë””ì–´ëŠ” ì´ ê³¼ì •ì„ ê·¸ëŒ€ë¡œ RAGì— ì ìš©í•œ ê²ƒì´ë‹¤. Basic RAGì—ì„œëŠ” LLMì´ retrieved documentsë¡œë¶€í„° ë°”ë¡œ ìµœì¢…ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ë˜ëŠ”ë°, ì´ ë°©ë²•ì€ **í”„ë¡¬í”„íŠ¸ ì²´ì¸ ê°œë…ì„ í™œìš©í•´ LLMìœ¼ë¡œ í•˜ì—¬ê¸ˆ í•œ ë²ˆ ë” ì •ë¦¬í•˜ëŠ” ì‹œê°„ì„ ê°–ê²Œí•˜ëŠ” ê²ƒ**ì´ë‹¤. ì •ë§ ë‹¨ìˆœí•œ ì ‘ê·¼ë²•ì´ë¼ ì´ë¯¸ ì œì•ˆë˜ì—ˆì„ ê²ƒì´ ë¶„ëª…í•œë°, ê´€ë ¨ ë‚´ìš©ì„ ì•„ì§ ì°¾ì§€ëŠ” ëª»í–ˆë‹¤(ë„ˆë¬´ ë‹¨ìˆœí•œ ì ‘ê·¼ì´ë¼ ì•„ì˜ˆ ì–¸ê¸‰ ìì²´ê°€ ì•ˆ ë˜ëŠ” ê²ƒì¸ê°€..ì œë³´í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤ğŸ™‚).

LLMì´ retrieved documentsë¡œë¶€í„° ê³§ë°”ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” Basic RAGì˜ ê²°ê³¼ì™€ ë¹„êµí–ˆì„ ë•Œ, ë™ì¼í•œ ë‹µë³€ ê¸¸ì´ì—ì„œ ì¢€ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì¶œë ¥í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. í•„ìê°€ êµ¬í˜„ ì¤‘ì¸ ì¢…êµì„œ/ì² í•™ì„œì™€ ê´€ë ¨í•œ RAG ì‹œìŠ¤í…œì—ì„œì˜ íš¨ê³¼ëŠ” ì´ëŸ°ë°, ë‹¤ë¥¸ ë¶„ì•¼ì˜ RAGì—ì„œëŠ” ì–´ë–¤ íš¨ê³¼ê°€ ìˆëŠ”ì§€ë„ ê¶ê¸ˆí•˜ë‹¤.  

```python
from operator import itemgetter
from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_anthropic import ChatAnthropic

# Embedding model
model_name = "BAAI/bge-m3"
model_kwargs = {'device': 'cuda'}
encode_kwargs = {"normalize_embeddings": True}
embedding = HuggingFaceBgeEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

# Loading vectorstore with Semantic-chunked data
vectorstore = FAISS.load_local(
    folder_path="C:\...",
    embeddings=embedding,
    index_name='index name'
    )

retriever = vectorstore.as_retriever(search_kwargs={"k":8})

question = "ìŠ¤í† ì•„ í•™íŒŒëŠ” ì¸ê°„ì´ ê³ í†µì— ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í•œë‹¤ê³  í–ˆë‚˜ìš”?"
retrieved_docs = retriever.get_relevant_documents(question)

# Generation
llm = ChatAnthropic(temperature=0, model_name="claude-3-haiku-20240307")
```

```python
template_1 = """

# Instruction

Given the following retrieved documents and the query, 
extract sentences or passages from the documents that are most relevant to answering the query. 
Then, provide **only ranked list of the top relevant sentences or passages**. 
Note that retrieved documents are delimited by XML tag of <retrieved_documents></retrieved_documents>.


# Query: {question}

<retrieved_documents>
# Retrieved Documents:
{context}
</retrieved_documents>


# Constraint:
1. Carefully read through each retrieved document and identify sentences or passages that are most relevant to answering the given query.
2. Extract the relevant sentences or passages and provide them as a numbered list.
3. Rank the extracted sentences or passages based on their relevance and potential to directly answer the query.
4. If there are no relevant sentences or passages found in the retrieved documents, indicate that no satisfactory answer was found.

# Output
Ranked list of the top relevant sentences or passages:
"""


prompt_1 = ChatPromptTemplate.from_template(template_1)
```

```python
 chain1 = (
    {"question": itemgetter("question"), "context": itemgetter("context")}
    | prompt_1
    | llm
    | StrOutputParser()
    )
```

```python
list_of_relevant_contents = chain1.invoke({"question": question, "context": retrieved_docs})

# list_of_relevant_contents
"""
1. ìŠ¤í† ì•„í•™íŒŒëŠ” ìš°ì£¼ì—ëŠ” 'ë¡œê³ ìŠ¤'ë¼ëŠ” ì‹ ì„±í•œ ì´ì„± êµ¬ì¡°ê°€ ì¡´ì¬í•œë‹¤ê³  ë¯¿ì—ˆìœ¼ë©°, ì´ ë¡œê³ ìŠ¤ì— ìˆœì‘í•˜ëŠ” ê²ƒì´ í–‰ë³µí•œ ì‚¶ì„ ì‚´ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë¼ê³  ê°€ë¥´ì³¤ë‹¤.
2. ìŠ¤í† ì•„í•™íŒŒëŠ” ê°ì„±ë³´ë‹¤ ì´ì„±ì— ì ˆëŒ€ ìš°ìœ„ë¥¼ ë‘ë©°, ê³ ë‚œì„ ê²¬ë”œ ìˆ˜ ì—†ê²Œ ë§Œë“œëŠ” ì••ë„ì ì¸ ê³ í†µì´ ì§‘ì°©ì—ì„œ ì˜¤ë¯€ë¡œ ì‚¶ì—ì„œ ë§ˆì£¼ì¹˜ëŠ” ê·¸ ë¬´ì—‡ì—ë„ ì§€ë‚˜ì¹˜ê²Œ ì• ì°©ì„ ê°–ì§€ ì•ŠëŠ” ë²•ì„ ë°°ì›Œì•¼ í•œë‹¤ê³  ì£¼ì¥í–ˆë‹¤.
3. ìŠ¤í† ì•„í•™íŒŒëŠ” ì£½ìŒì´ í•œ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œ íƒˆë°”ê¿ˆí•˜ëŠ” ì¼ì¼ ë¿ì´ë¼ê³  ê°€ë¥´ì³¤ìœ¼ë©°, ì£½ìŒì— ëŒ€í•œ ë‘ë ¤ì›€ì—ì„œ ë²—ì–´ë‚˜ í˜„ì¬ë¥¼ ì‚¬ë‘í•˜ë©° ì‚´ì•„ê°€ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í–ˆë‹¤.
"""
```

```python
template_2 = """
   
# Instruction
Using the provided ranked list of the top relevant sentences or passages extracted from the retrieved documents, 
generate a final answer to the given query. 
Synthesize the information from the ranked list of the top relevant sentences or passages to create a coherent, logical, comprehensive, and concise response.

# Query: {question}

Ranked list of the top relevant sentences or passages:
{list_of_relevant_contents}

# Constraint:
1. Carefully review the provided list of the top relevant sentences or passages and identify the key information relevant to the query.
2. Synthesize the information from the ranked list of the top relevant sentences or passages to generate a final answer that directly addresses the query.
3. You DO NOT need to use all the information from the ranked list of the top relevant sentences or passages when generating a final answer.
4. Ensure that the final answer is coherent, logical, comprehensive, and concise. Rule out sentences or passages that make your final answer less than coherent and logical. 
5. If the ranked list of the top relevant sentences or passages do not provide sufficient information to answer the query satisfactorily, indicate that more information may be needed.
6. Use your own words to create a natural and fluent response, while maintaining the accuracy of the information provided in the ranked list of the top relevant sentences or passages.

# Output
Final Answer:
"""


prompt_2 = ChatPromptTemplate.from_template(template_2)
```

```python
chain2 = (
    {"question": itemgetter("question"), "list_of_relevant_contents": itemgetter("list_of_relevant_contents")}
    | prompt_2
    | llm
    | StrOutputParser()
    )
```

```python
final_answer = chain2.invoke({"question":question, "list_of_relevant_contents":list_of_relevant_contents})

# final_answer
"""
"ìŠ¤í† ì•„ í•™íŒŒëŠ” ì¸ê°„ì´ ê³ í†µì— ëŒ€ì²˜í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê²¬í•´ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.

ì²«ì§¸, ìŠ¤í† ì•„ í•™íŒŒëŠ” ìš°ì£¼ì—ëŠ” 'ë¡œê³ ìŠ¤'ë¼ëŠ” ì‹ ì„±í•œ ì´ì„± êµ¬ì¡°ê°€ ì¡´ì¬í•œë‹¤ê³  ë¯¿ì—ˆìœ¼ë©°, ì´ ë¡œê³ ìŠ¤ì— ìˆœì‘í•˜ëŠ” ê²ƒì´ í–‰ë³µí•œ ì‚¶ì„ ì‚´ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë¼ê³  ê°€ë¥´ì³¤ìŠµë‹ˆë‹¤. 
ì¦‰, ê°ì„±ë³´ë‹¤ ì´ì„±ì— ì ˆëŒ€ ìš°ìœ„ë¥¼ ë‘ë©°, ê³ ë‚œì„ ê²¬ë”œ ìˆ˜ ì—†ê²Œ ë§Œë“œëŠ” ì••ë„ì ì¸ ê³ í†µì´ ì§‘ì°©ì—ì„œ ì˜¤ë¯€ë¡œ ì‚¶ì—ì„œ ë§ˆì£¼ì¹˜ëŠ” ê·¸ ë¬´ì—‡ì—ë„ ì§€ë‚˜ì¹˜ê²Œ ì• ì°©ì„ ê°–ì§€ ì•ŠëŠ” ë²•ì„ ë°°ì›Œì•¼ í•œë‹¤ê³  ì£¼ì¥í–ˆìŠµë‹ˆë‹¤.

ë‘˜ì§¸, ìŠ¤í† ì•„ í•™íŒŒëŠ” ì£½ìŒì´ í•œ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œ íƒˆë°”ê¿ˆí•˜ëŠ” ì¼ì¼ ë¿ì´ë¼ê³  ê°€ë¥´ì³¤ìœ¼ë©°, ì£½ìŒì— ëŒ€í•œ ë‘ë ¤ì›€ì—ì„œ ë²—ì–´ë‚˜ í˜„ì¬ë¥¼ ì‚¬ë‘í•˜ë©° ì‚´ì•„ê°€ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ ìŠ¤í† ì•„ í•™íŒŒëŠ” ì¸ê°„ì´ ê³ í†µì— ëŒ€ì²˜í•˜ê¸° ìœ„í•´ì„œëŠ” ì´ì„±ì— ì˜í•´ ì§€ë°°ë˜ì–´ì•¼ í•˜ë©°, ì‚¶ì— ëŒ€í•œ ì§‘ì°©ì„ ë²„ë¦¬ê³  í˜„ì¬ì— ì¶©ì‹¤í•˜ê²Œ ì‚´ì•„ê°€ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ì£¼ì¥í–ˆìŠµë‹ˆë‹¤."
"""
```


### cf) Basic RAG ê²°ê³¼

```
# Your role
You are a brilliant assistant for question-answering tasks.

# Instruction
Your task is to answer the question using the following pieces of retrieved context.
When you generate an answer, follow the steps in order.
1. Think deeply and multiple times about the user's question\nUser's question:\n{question}\nYou must understand the intent of their question and provide the most appropriate answer.
2. Choose the most relevant content from the retrieved context that addresses the user's question and use it to generate an answer.

Retrieved Context:
{context}


# Constraint
- Each sentence that is generated should be well-connected and logical.
- If you don't know the answer, just say that you don't know.
- Use five sentences maximum. Keep the answer concise but logical/natural/in-depth.
-  **Answer in Korean.**

Question:
{question}
```

```
'ìŠ¤í† ì•„ í•™íŒŒëŠ” ì¸ê°„ì´ ê³ í†µì— ëŒ€ì²˜í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì„¸ ê°€ì§€ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤. 

ì²«ì§¸, ì˜ˆìƒì¹˜ ëª»í•œ ê³ ë‚œê³¼ ì—­ê²½ì„ ì‹ ì˜ ì„­ë¦¬ì´ì ê²°êµ­ ìœ ìµì´ ë˜ëŠ” ì—­ì‚¬ë¡œ ë°›ì•„ë“¤ì´ëŠ” ìì„¸ë¥¼ ê°€ì ¸ì•¼ í•œë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. 
ìŠ¤í† ì•„ í•™íŒŒëŠ” ìš°ì£¼ê°€ ì‹ ì„±í•˜ê³  ì´ì„±ì ì´ë©° ì™„ë²½í•œ ì§ˆì„œë¥¼ ìœ ì§€í•˜ê³  ìˆë‹¤ê³  ë¯¿ì—ˆê¸° ë•Œë¬¸ì—, ì„¸ìƒì´ ë³´ë‚´ì£¼ëŠ” ê²ƒì„ ì „í­ì ìœ¼ë¡œ ë°›ì•„ë“¤ì´ëŠ” ì‚¶ì„ ì‚´ì•„ì•¼ í•œë‹¤ê³  ì£¼ì¥í–ˆìŠµë‹ˆë‹¤.

ë‘˜ì§¸, ê°ì„±ë³´ë‹¤ ì´ì„±ì— ì ˆëŒ€ ìš°ìœ„ë¥¼ ë‘ë©°, ê³ ë‚œì„ ê²¬ë”œ ìˆ˜ ì—†ê²Œ ë§Œë“œëŠ” ì••ë„ì ì¸ ê³ í†µì´ ì§‘ì°©ì—ì„œ ì˜¤ë¯€ë¡œ ì‚¶ì—ì„œ ë§ˆì£¼ì¹˜ëŠ” ê·¸ ë¬´ì—‡ì—ë„ ì§€ë‚˜ì¹˜ê²Œ ì• ì°©ì„ ê°–ì§€ ì•ŠëŠ” ë²•ì„ ë°°ì›Œì•¼ í•œë‹¤ê³  í–ˆìŠµë‹ˆë‹¤.

ì…‹ì§¸, ì£½ìŒì€ í•œ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œ íƒˆë°”ê¿ˆí•˜ëŠ” ì¼ì¼ ë¿ì´ë¼ëŠ” ìŠ¤í† ì•„ ì‚¬ìƒì„ í†µí•´, ì£½ìŒì— ëŒ€í•œ ë‘ë ¤ì›€ì„ ê·¹ë³µí•˜ê³  êµ¬ì›ê³¼ ë¹„ìŠ·í•œ ê²½ì§€ì— ì´ë¥´ê²Œ ëœë‹¤ê³  ì£¼ì¥í–ˆìŠµë‹ˆë‹¤.'
```


## References

[1] Anthropic. n.d. ["Chain prompts." In Prompt Engineering.](https://docs.anthropic.com/claude/docs/chain-prompts) Accessed March 28, 2024. https://docs.anthropic.com/claude/docs/chain-prompts{:target="_blank"}  
[2] Arjun, [Improving RAG: using LLMs as reranking agents](https://medium.com/@arjunkmrm/improving-rag-using-llms-as-re-ranking-agents-a6c66839dee5){:target="_blank"} Medium, 2024, https://medium.com/@arjunkmrm/improving-rag-using-llms-as-re-ranking-agents-a6c66839dee5{:target="_blank"}  
[3] L. Martin, [RAG from scratch: Part 6. Query Translation (RAG-Fusion)](https://www.youtube.com/watch?v=77qELPbNgxA&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=6){:target="_blank"}  
[4] B. Ghosh, [Blueprint for Building Corrective RAG (CRAG)](https://medium.com/@bijit211987/blueprint-for-building-corrective-rag-crag-d6fbfeb7c98e){:target="_blank"} Medium, 2024, https://medium.com/@bijit211987/blueprint-for-building-corrective-rag-crag-d6fbfeb7c98e{:target="_blank"}  